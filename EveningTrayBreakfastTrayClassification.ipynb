{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fszbewg89uYp",
        "outputId": "5b67aea3-20a3-403c-c362-f65e2fa4f683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yZgGeXvd-3z7"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/eveningTrayBreakfastTray.zip\", \"eveningTrayBreakfastTray/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELUOsuT2iluZ",
        "outputId": "ef9e14b1-c180-4f0c-fbb1-772689e4085c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['test', 'valid', 'training']\n",
            "['test', 'valid', 'training']\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "from IPython.display import display_html\n",
        " \n",
        "\n",
        "import numpy as np  \n",
        "import pandas as pd  \n",
        "\n",
        " \n",
        "\n",
        "import os\n",
        "print(os.listdir(\"/content/dinnerTrayBreakfastTrayy/yeni\"))\n",
        "dataDirectory= \"/content/dinnerTrayBreakfastTrayy/yeni\"\n",
        "print(os.listdir(dataDirectory))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMHtrm1MixO0",
        "outputId": "47af4d85-774c-4678-dc7d-69bff425383f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0', '1']\n",
            "['0', '1']\n"
          ]
        }
      ],
      "source": [
        "train_path = dataDirectory+'/training'\n",
        "test_path  = dataDirectory+'/valid'\n",
        "print(os.listdir(train_path))\n",
        "print(os.listdir(test_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGCl7MoWixd3"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode='nearest',\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ortBbhB8i-d2"
      },
      "outputs": [],
      "source": [
        "selectedClasses = ['0', '1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyJPywXYjemP"
      },
      "outputs": [],
      "source": [
        "train_path = '/content/eveningTrayBreakfastTray/eveningTrayBreakfastTray/training'\n",
        "test_path  = '/content/eveningTrayBreakfastTray/eveningTrayBreakfastTray/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eol1EBs1ixhB",
        "outputId": "5b155169-18d7-466e-ba61-f0bd5060a9bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1166 images belonging to 2 classes.\n",
            "Found 290 images belonging to 2 classes.\n",
            "Found 1082 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "batchSize=32\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batchSize,\n",
        "    classes=selectedClasses,\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_path, # same directory as training data\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batchSize,\n",
        "    classes=selectedClasses,\n",
        "    subset='validation') # set as validation data\n",
        "\n",
        "test_generator = ImageDataGenerator().flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(224,224),\n",
        "    classes=selectedClasses,\n",
        "    shuffle= False,\n",
        "    batch_size = batchSize)# set as test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np70J7s2ixmD",
        "outputId": "03180208-a53b-4952-c689-be160c0f2369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In train_generator \n",
            "0 :\t 583\n",
            "1 :\t 583\n",
            "\n",
            "In validation_generator \n",
            "0 :\t 145\n",
            "1 :\t 145\n",
            "\n",
            "In test_generator \n",
            "0 :\t 530\n",
            "1 :\t 552\n"
          ]
        }
      ],
      "source": [
        "print (\"In train_generator \")\n",
        "for cls in range(len (train_generator.class_indices)):\n",
        "    print(selectedClasses[cls],\":\\t\",list(train_generator.classes).count(cls))\n",
        "print (\"\")\n",
        "\n",
        "print (\"In validation_generator \")\n",
        "for cls in range(len (validation_generator.class_indices)):\n",
        "    print(selectedClasses[cls],\":\\t\",list(validation_generator.classes).count(cls))\n",
        "print (\"\")\n",
        "\n",
        "print (\"In test_generator \")\n",
        "for cls in range(len (test_generator.class_indices)):\n",
        "    print(selectedClasses[cls],\":\\t\",list(test_generator.classes).count(cls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4pXPCN4ixou",
        "outputId": "9ff72da5-3916-4517-f3b2-a547bb18d476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In train_generator \n",
            "0 :\t 583\n",
            "1 :\t 583\n",
            "\n",
            "In validation_generator \n",
            "0 :\t 145\n",
            "1 :\t 145\n",
            "\n",
            "In test_generator \n",
            "0 :\t 530\n",
            "1 :\t 552\n"
          ]
        }
      ],
      "source": [
        "print (\"In train_generator \")\n",
        "for cls in range(len (train_generator.class_indices)):\n",
        "    print(selectedClasses[cls],\":\\t\",list(train_generator.classes).count(cls))\n",
        "print (\"\")\n",
        "\n",
        "print (\"In validation_generator \")\n",
        "for cls in range(len (validation_generator.class_indices)):\n",
        "    print(selectedClasses[cls],\":\\t\",list(validation_generator.classes).count(cls))\n",
        "print (\"\")\n",
        "\n",
        "print (\"In test_generator \")\n",
        "for cls in range(len (test_generator.class_indices)):\n",
        "    print(selectedClasses[cls],\":\\t\",list(test_generator.classes).count(cls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peRaMAiVjtuQ"
      },
      "outputs": [],
      "source": [
        "train_generator.reset()\n",
        "imgs, labels = train_generator.next()\n",
        "\n",
        "#print(labels)\n",
        "\n",
        "labelNames=[]\n",
        "labelIndices=[np.where(r==1)[0][0] for r in labels]\n",
        "#print(labelIndices)\n",
        "\n",
        "for ind in labelIndices:\n",
        "    for labelName,labelIndex in train_generator.class_indices.items():\n",
        "        if labelIndex == ind:\n",
        "            #print (labelName)\n",
        "            labelNames.append(labelName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZyIk9Gc9uJp",
        "outputId": "c2c9d577-4284-4423-d5fe-7985219a0db8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        " \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.applications import VGG16\n",
        " \n",
        "num_classes=2\n",
        "IMAGE_SHAPE = [224, 224]   \n",
        "batch_size=32\n",
        " \n",
        "vgg = VGG16(input_shape = (224,224,3), weights = 'imagenet', include_top = False)  \n",
        "\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(vgg.output)\n",
        "x = Dense(128, activation = 'relu')(x)    \n",
        "x = Dense(64, activation = 'relu')(x)\n",
        "x = Dense(num_classes, activation = 'softmax')(x)   \n",
        "\n",
        "model = Model(inputs = vgg.input, outputs = x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFUZK6es94JJ",
        "outputId": "128b7255-ca02-4eaf-ae84-0409c5716aec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1456 images belonging to 2 classes.\n",
            "Found 1082 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "trdata = ImageDataGenerator()\n",
        "train_data_gen = trdata.flow_from_directory(directory=\"/content/eveningTrayBreakfastTray/eveningTrayBreakfastTray/training\",target_size=(224,224),shuffle=False, class_mode='categorical')\n",
        "tsdata = ImageDataGenerator()\n",
        "test_data_gen = tsdata.flow_from_directory(directory=\"/content/eveningTrayBreakfastTray/eveningTrayBreakfastTray/test\", target_size=(224,224),shuffle=False, class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut_1lk2J9wN9",
        "outputId": "ae09bbd5-8bf1-4771-eccc-7f3838f629aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-91602d82b911>:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_data_gen, steps_per_epoch=training_steps_per_epoch, validation_data=test_data_gen, validation_steps=validation_steps_per_epoch,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "46/46 [==============================] - 85s 2s/step - loss: 3.6285 - accuracy: 0.9155 - val_loss: 0.0804 - val_accuracy: 0.9945\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 59s 1s/step - loss: 0.8947 - accuracy: 0.9815 - val_loss: 0.0640 - val_accuracy: 0.9972\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.1175 - accuracy: 0.9966 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 59s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 75s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 73s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 57s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 58s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 62s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 58s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 75s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 73s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 75s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 58s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 59s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 74s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 59s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 76s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 59s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 61s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 74s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 59s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 75s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 75s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 62s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 59s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 60s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Training Completed!\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "epochs = 50\n",
        "#checkpoint = ModelCheckpoint(filepath='finalvgg16model.h5', verbose=1, save_best_only=True)\n",
        "training_steps_per_epoch = np.ceil(train_data_gen.samples / batch_size)\n",
        "validation_steps_per_epoch = np.ceil(test_data_gen.samples / batch_size)\n",
        "\n",
        "model.fit_generator(train_data_gen, steps_per_epoch=training_steps_per_epoch, validation_data=test_data_gen, validation_steps=validation_steps_per_epoch,\n",
        "                        epochs=epochs, verbose=1)\n",
        "print('Training Completed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gai3r9W39wRY",
        "outputId": "e6b20720-0aca-4e2d-c41a-cc896aeec472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 27s 757ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       530\n",
            "           1       1.00      1.00      1.00       552\n",
            "\n",
            "    accuracy                           1.00      1082\n",
            "   macro avg       1.00      1.00      1.00      1082\n",
            "weighted avg       1.00      1.00      1.00      1082\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Y_pred = model.predict(test_data_gen, test_data_gen.samples / batch_size)\n",
        "val_preds = np.argmax(Y_pred, axis=1)\n",
        "import sklearn.metrics as metrics\n",
        "val_trues =test_data_gen.classes\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_trues, val_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5TIS3HNAIRm",
        "outputId": "b5e33a9c-3bcb-43b3-ac6a-c5cc9dc1ee57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-981ad33596cb>:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  tf.keras.models.save_model(model,keras_file)\n"
          ]
        }
      ],
      "source": [
        "keras_file=\"Model.h5\"\n",
        "tf.keras.models.save_model(model,keras_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtBOTTZyAJxA",
        "outputId": "ac56c4ae-47a1-40e4-d36e-61b7ea0e22bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "eveningTray\n"
          ]
        }
      ],
      "source": [
        "#Test the model\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "img_path = '/content/test.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds=model.predict(x)\n",
        "# create a list containing the class labels\n",
        "class_labels = ['eveningTray','breakfastTray']\n",
        "\n",
        "# find the index of the class with maximum score\n",
        "pred = np.argmax(preds, axis=-1)\n",
        "\n",
        "# print the label of the class with maximum score\n",
        "print(class_labels[pred[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYC7ZFVeBOpp",
        "outputId": "c748a84a-815e-491d-ce4b-71a681b586f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "71747596"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model('/content/Model.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(\"trayType.tflite\", \"wb\").write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
