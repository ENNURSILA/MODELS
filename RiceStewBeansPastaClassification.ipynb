{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9jCrhbThv4S",
        "outputId": "c4e3d4c9-0c5c-4f2d-ca05-f81ffa407df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Dtp2XCinhv6r"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/dinnerFoodTypes.zip\", \"dinnerFoodTypes/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_0ORdt5hv9Q",
        "outputId": "6d038e29-944c-494b-c0c4-754e07fe04c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['test', 'train', 'valid']\n",
            "['test', 'train', 'valid']\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "from IPython.display import display_html\n",
        "\n",
        " \n",
        "\n",
        "import numpy as np  \n",
        "import pandas as pd  \n",
        "\n",
        " \n",
        "\n",
        "import os\n",
        "print(os.listdir(\"/content/dinnerFoodTypes/dinnerFoodTypes\"))\n",
        "dataDirectory= \"/content/dinnerFoodTypes/dinnerFoodTypes\"\n",
        "print(os.listdir(dataDirectory))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r55XGiahwAx",
        "outputId": "b7693e38-6f08-43d1-d04a-58b96a6dd64d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1', '0', '3', '2']\n",
            "['1', '0', '3', '2']\n"
          ]
        }
      ],
      "source": [
        "train_path = dataDirectory+'/train'\n",
        "test_path  = dataDirectory+'/valid'\n",
        "print(os.listdir(train_path))\n",
        "print(os.listdir(test_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H4fmv6Wlimaq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.applications.inception_v3 import decode_predictions\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import model_from_json\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import keras.applications.xception as xception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "imv5eG87iiMA"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode='nearest',\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SS8CsvuniiOx"
      },
      "outputs": [],
      "source": [
        "selectedClasses = ['0', '1','2','3']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0LqYtnkWisFJ"
      },
      "outputs": [],
      "source": [
        "train_path = '/content/dinnerFoodTypes/dinnerFoodTypes/train'\n",
        "test_path  = '/content/dinnerFoodTypes/dinnerFoodTypes/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD7-e3iLisJF",
        "outputId": "ec404dcc-92a1-404e-9ebf-9bce490c6728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1256 images belonging to 4 classes.\n",
            "Found 312 images belonging to 4 classes.\n",
            "Found 150 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "batchSize=32\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batchSize,\n",
        "    classes=selectedClasses,\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_path, # same directory as training data\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batchSize,\n",
        "    classes=selectedClasses,\n",
        "    subset='validation') # set as validation data\n",
        "\n",
        "test_generator = ImageDataGenerator().flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(224,224),\n",
        "    classes=selectedClasses,\n",
        "    shuffle= False,\n",
        "    batch_size = batchSize)# set as test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30AenO1oiwnL",
        "outputId": "128680d9-3ded-4cae-c6c3-18104b96c6f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In train_generator \n",
            "0 :\t 474\n",
            "1 :\t 410\n",
            "2 :\t 100\n",
            "3 :\t 272\n",
            "\n",
            "In validation_generator \n",
            "0 :\t 118\n",
            "1 :\t 102\n",
            "2 :\t 25\n",
            "3 :\t 67\n",
            "\n",
            "In test_generator \n",
            "0 :\t 72\n",
            "1 :\t 67\n",
            "2 :\t 9\n",
            "3 :\t 2\n"
          ]
        }
      ],
      "source": [
        "print (\"In train_generator \")\n",
        "for cls in range(len (train_generator.class_indices)):\n",
        "    print(selectedClasses[cls],\":\\t\",list(train_generator.classes).count(cls))\n",
        "print (\"\")\n",
        "\n",
        "print (\"In validation_generator \")\n",
        "for cls in range(len (validation_generator.class_indices)):\n",
        "    print(selectedClasses[cls],\":\\t\",list(validation_generator.classes).count(cls))\n",
        "print (\"\")\n",
        "\n",
        "print (\"In test_generator \")\n",
        "for cls in range(len (test_generator.class_indices)):\n",
        "    print(selectedClasses[cls],\":\\t\",list(test_generator.classes).count(cls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yTYs_FNviwst"
      },
      "outputs": [],
      "source": [
        "train_generator.reset()\n",
        "imgs, labels = train_generator.next()\n",
        "\n",
        "#print(labels)\n",
        "\n",
        "labelNames=[]\n",
        "labelIndices=[np.where(r==1)[0][0] for r in labels]\n",
        "#print(labelIndices)\n",
        "\n",
        "for ind in labelIndices:\n",
        "    for labelName,labelIndex in train_generator.class_indices.items():\n",
        "        if labelIndex == ind:\n",
        "            #print (labelName)\n",
        "            labelNames.append(labelName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1Nw-Zwzi6-9",
        "outputId": "b22ef778-1d9a-4b0c-c4e0-aeadff797fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.applications import VGG16\n",
        "num_classes=4\n",
        "IMAGE_SHAPE = [224, 224]  \n",
        "batch_size=32\n",
        "vgg = VGG16(input_shape = (224,224,3), weights = 'imagenet', include_top = False)  \n",
        "\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(vgg.output)\n",
        "x = Dense(128, activation = 'relu')(x)    \n",
        "x = Dense(64, activation = 'relu')(x)\n",
        "x = Dense(num_classes, activation = 'softmax')(x)   \n",
        "\n",
        "model = Model(inputs = vgg.input, outputs = x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWXzuRTei7Cf",
        "outputId": "0ceb179a-f15f-4038-9274-165689d0352b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1568 images belonging to 4 classes.\n",
            "Found 150 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "trdata = ImageDataGenerator()\n",
        "train_data_gen = trdata.flow_from_directory(directory=\"/content/dinnerFoodTypes/dinnerFoodTypes/train\",target_size=(224,224),shuffle=False, class_mode='categorical')\n",
        "tsdata = ImageDataGenerator()\n",
        "test_data_gen = tsdata.flow_from_directory(directory=\"/content/dinnerFoodTypes/dinnerFoodTypes/test\", target_size=(224,224),shuffle=False, class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IBcFe1AjZza",
        "outputId": "d3dfc23f-ad00-41d2-ea66-320a4bea8afe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-15-a33cba508e89>:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_data_gen, steps_per_epoch=training_steps_per_epoch, validation_data=test_data_gen, validation_steps=validation_steps_per_epoch,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "49/49 [==============================] - 30s 424ms/step - loss: 21.6780 - accuracy: 0.6448 - val_loss: 3.7162 - val_accuracy: 0.9000\n",
            "Epoch 2/50\n",
            "49/49 [==============================] - 16s 321ms/step - loss: 1.7492 - accuracy: 0.8807 - val_loss: 4.4011e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "49/49 [==============================] - 15s 302ms/step - loss: 0.2900 - accuracy: 0.9726 - val_loss: 2.3565e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "49/49 [==============================] - 16s 316ms/step - loss: 0.1075 - accuracy: 0.9923 - val_loss: 0.0126 - val_accuracy: 0.9867\n",
            "Epoch 5/50\n",
            "49/49 [==============================] - 15s 313ms/step - loss: 0.1207 - accuracy: 0.9943 - val_loss: 4.3869e-07 - val_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "49/49 [==============================] - 16s 321ms/step - loss: 0.0649 - accuracy: 0.9911 - val_loss: 8.8641e-06 - val_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "49/49 [==============================] - 16s 318ms/step - loss: 0.0567 - accuracy: 0.9949 - val_loss: 2.1063e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "49/49 [==============================] - 17s 342ms/step - loss: 0.0374 - accuracy: 0.9968 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "49/49 [==============================] - 15s 311ms/step - loss: 0.0758 - accuracy: 0.9904 - val_loss: 5.3828e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "49/49 [==============================] - 15s 314ms/step - loss: 0.0733 - accuracy: 0.9917 - val_loss: 2.5511e-07 - val_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "49/49 [==============================] - 15s 312ms/step - loss: 0.5607 - accuracy: 0.9452 - val_loss: 1.4351e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "49/49 [==============================] - 16s 331ms/step - loss: 0.0906 - accuracy: 0.9879 - val_loss: 1.6194e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "49/49 [==============================] - 16s 318ms/step - loss: 0.1330 - accuracy: 0.9943 - val_loss: 6.5167e-08 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "49/49 [==============================] - 16s 318ms/step - loss: 0.0447 - accuracy: 0.9974 - val_loss: 1.5895e-09 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "49/49 [==============================] - 16s 330ms/step - loss: 0.0613 - accuracy: 0.9974 - val_loss: 5.5631e-09 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "49/49 [==============================] - 16s 310ms/step - loss: 0.0546 - accuracy: 0.9981 - val_loss: 2.3842e-08 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "49/49 [==============================] - 16s 312ms/step - loss: 0.0163 - accuracy: 0.9987 - val_loss: 7.9473e-10 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "49/49 [==============================] - 16s 312ms/step - loss: 0.0411 - accuracy: 0.9987 - val_loss: 1.5576e-07 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "49/49 [==============================] - 15s 315ms/step - loss: 0.0245 - accuracy: 0.9987 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "49/49 [==============================] - 15s 311ms/step - loss: 0.0423 - accuracy: 0.9987 - val_loss: 1.7484e-08 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "49/49 [==============================] - 17s 343ms/step - loss: 0.0250 - accuracy: 0.9987 - val_loss: 1.5895e-09 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "49/49 [==============================] - 16s 333ms/step - loss: 0.0345 - accuracy: 0.9987 - val_loss: 2.7259e-07 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "49/49 [==============================] - 16s 320ms/step - loss: 0.0631 - accuracy: 0.9974 - val_loss: 7.0730e-08 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "49/49 [==============================] - 15s 314ms/step - loss: 0.0483 - accuracy: 0.9974 - val_loss: 2.6464e-07 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "49/49 [==============================] - 15s 315ms/step - loss: 0.0246 - accuracy: 0.9987 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "49/49 [==============================] - 15s 311ms/step - loss: 0.0452 - accuracy: 0.9987 - val_loss: 1.4305e-08 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "49/49 [==============================] - 15s 310ms/step - loss: 0.0250 - accuracy: 0.9987 - val_loss: 3.9736e-09 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "49/49 [==============================] - 16s 326ms/step - loss: 0.0618 - accuracy: 0.9974 - val_loss: 6.3578e-09 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "49/49 [==============================] - 17s 341ms/step - loss: 0.0376 - accuracy: 0.9987 - val_loss: 2.3047e-08 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "49/49 [==============================] - 15s 311ms/step - loss: 0.0240 - accuracy: 0.9987 - val_loss: 9.5367e-09 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "49/49 [==============================] - 15s 309ms/step - loss: 0.0359 - accuracy: 0.9987 - val_loss: 1.7166e-07 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "49/49 [==============================] - 16s 319ms/step - loss: 0.0290 - accuracy: 0.9987 - val_loss: 2.1458e-08 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "49/49 [==============================] - 15s 313ms/step - loss: 0.0334 - accuracy: 0.9987 - val_loss: 8.6859e-07 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "49/49 [==============================] - 15s 315ms/step - loss: 0.0592 - accuracy: 0.9974 - val_loss: 4.0531e-08 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "49/49 [==============================] - 16s 318ms/step - loss: 0.0262 - accuracy: 0.9987 - val_loss: 1.7484e-08 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "49/49 [==============================] - 16s 317ms/step - loss: 0.0346 - accuracy: 0.9987 - val_loss: 1.0800e-06 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "49/49 [==============================] - 17s 340ms/step - loss: 0.0694 - accuracy: 0.9968 - val_loss: 4.1245e-07 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "49/49 [==============================] - 16s 318ms/step - loss: 0.1467 - accuracy: 0.9936 - val_loss: 0.0154 - val_accuracy: 0.9933\n",
            "Epoch 39/50\n",
            "49/49 [==============================] - 15s 313ms/step - loss: 2.9485 - accuracy: 0.8858 - val_loss: 8.5275 - val_accuracy: 0.6867\n",
            "Epoch 40/50\n",
            "49/49 [==============================] - 17s 340ms/step - loss: 12.8935 - accuracy: 0.7768 - val_loss: 1.6208 - val_accuracy: 0.9733\n",
            "Epoch 41/50\n",
            "49/49 [==============================] - 16s 317ms/step - loss: 0.6393 - accuracy: 0.9719 - val_loss: 4.5165e-05 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "49/49 [==============================] - 15s 311ms/step - loss: 0.3560 - accuracy: 0.9847 - val_loss: 7.9473e-10 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "49/49 [==============================] - 15s 316ms/step - loss: 0.0784 - accuracy: 0.9885 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "49/49 [==============================] - 16s 329ms/step - loss: 0.0393 - accuracy: 0.9968 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "49/49 [==============================] - 16s 319ms/step - loss: 0.0229 - accuracy: 0.9962 - val_loss: 1.3510e-08 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "49/49 [==============================] - 16s 317ms/step - loss: 0.0221 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "49/49 [==============================] - 16s 321ms/step - loss: 0.0556 - accuracy: 0.9930 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "49/49 [==============================] - 17s 340ms/step - loss: 0.0129 - accuracy: 0.9974 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "49/49 [==============================] - 16s 316ms/step - loss: 0.0262 - accuracy: 0.9962 - val_loss: 3.1789e-09 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "49/49 [==============================] - 16s 319ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Training Completed!\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "epochs = 50\n",
        "checkpoint = ModelCheckpoint(filepath='/content/finalvgg16model.h5', verbose=1, save_best_only=True)\n",
        "training_steps_per_epoch = np.ceil(train_data_gen.samples / batch_size)\n",
        "validation_steps_per_epoch = np.ceil(test_data_gen.samples / batch_size)\n",
        "\n",
        "model.fit_generator(train_data_gen, steps_per_epoch=training_steps_per_epoch, validation_data=test_data_gen, validation_steps=validation_steps_per_epoch,\n",
        "                        epochs=epochs, verbose=1)\n",
        "print('Training Completed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yx5dChNi7KV",
        "outputId": "df43bd83-91d9-4412-bc85-af66945c480e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 405ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        72\n",
            "           1       1.00      1.00      1.00        67\n",
            "           2       1.00      1.00      1.00         9\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00       150\n",
            "   macro avg       1.00      1.00      1.00       150\n",
            "weighted avg       1.00      1.00      1.00       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Y_pred = model.predict(test_data_gen, test_data_gen.samples / batch_size)\n",
        "val_preds = np.argmax(Y_pred, axis=1)\n",
        "import sklearn.metrics as metrics\n",
        "val_trues =test_data_gen.classes\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_trues, val_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9onGAw4Wo8F_",
        "outputId": "fc0a7d39-6b39-436b-d11d-6954b7096262"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-e4483b396b19>:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  tf.keras.models.save_model(model,keras_file)\n"
          ]
        }
      ],
      "source": [
        "keras_file=\"dinnerfoodtype.h5\"\n",
        "tf.keras.models.save_model(model,keras_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8EDqO6-pkhU",
        "outputId": "5bc523f4-0a05-419f-8ac7-b6f0158c20e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "71748116"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model('/content/dinnerfoodtype.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(\"dinnerfoodtype.tflite\", \"wb\").write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJYKPy_IpCH9",
        "outputId": "ca156d3a-6227-4d5c-ad6b-02a1ff0823f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "rice\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "img_path = '/content/mytest.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds=model.predict(x)\n",
        "# create a list containing the class labels\n",
        "class_labels = ['rice','stew','beans','pasta']\n",
        "\n",
        "# find the index of the class with maximum score\n",
        "pred = np.argmax(preds, axis=-1)\n",
        "\n",
        "# print the label of the class with maximum score\n",
        "print(class_labels[pred[0]])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
